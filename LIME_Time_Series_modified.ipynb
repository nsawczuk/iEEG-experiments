{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca4f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FROM https://github.com/mdhabibi/LIME-for-Time-Series\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from numpy import argmax\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('X.csv')\n",
    "y=pd.read_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = to_categorical(y, num_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.1, stratify=y_one_hot, shuffle=True, random_state=10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, shuffle=True, random_state=10)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "\n",
    "def make_model(input_shape,units):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=int(units[0]), kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=int(units[1]), kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=int(units[2]), kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model = make_model((X.shape[1],X.shape[2]),[64,128,64])\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "                                                      class_weight = \"balanced\",\n",
    "                                                      classes = np.unique(y_train[:,0]),\n",
    "                                                      y = y_train[:,0]\n",
    "                                                  )\n",
    "class_weights = dict(zip(np.unique(y_train[:,0]), class_weights))\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 128\n",
    "optimizer = keras.optimizers.Adam(learning_rate=float(0.01))\n",
    "model.compile(  optimizer='adam',\n",
    "                loss= \"binary_crossentropy\",\n",
    "                    metrics=[\n",
    "                    keras.metrics.AUC(),\n",
    "                ],)\n",
    "callbacks = [keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\", factor=0.5, patience=25, min_lr=0.0001    ),\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1),]        # Train the CNN model\n",
    "model.fit( X_train,\n",
    "                  y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(X_val,y_val),\n",
    "                  verbose=1,\n",
    "                  class_weight=class_weights,\n",
    "              )\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "# save the trained model\n",
    "model.save('model')\n",
    "\n",
    "\n",
    "# Create the probability vector for each instances in test dataset\n",
    "probability_vectors = model.predict(X_test)\n",
    "print(\"Shape of probability_vector (number of rows in test dataset, number of classes):\", probability_vectors.shape)\n",
    "print(\"Predicted Classes:\", probability_vectors)\n",
    "\n",
    "print('ROC AUC:', roc_auc_score(y_test,probability_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f7e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FROM https://github.com/mdhabibi/LIME-for-Time-Series\n",
    "\n",
    "def generate_random_perturbations_matrix(num_perturbations, num_slices,channels):\n",
    "    \"\"\"\n",
    "    Generates random perturbations for ECG signal segments.\n",
    "    \n",
    "    This function creates a binary matrix where each row represents a perturbation,\n",
    "    and each column corresponds to a segment of the ECG signal. A value of '1' indicates\n",
    "    the segment is active or unchanged, while '0' indicates the segment is inactive or altered.\n",
    "    \n",
    "    Parameters:\n",
    "        num_perturbations (int): The number of perturbations to generate.\n",
    "        num_slices (int): The number of slices (segments) each ECG signal is divided into.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A binary matrix representing random perturbations.\n",
    "    \"\"\"\n",
    "    random_perturbations = np.random.binomial(1, 0.5, size=(num_perturbations, num_slices, channels))\n",
    "    return random_perturbations\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def analyze_prediction(probability_vector, class_labels):\n",
    "    \"\"\"\n",
    "    Analyzes the probability vector from a model prediction, returning the top predicted classes\n",
    "    and the most likely predicted class.\n",
    "    \n",
    "    Parameters:\n",
    "        probability_vector (np.ndarray): The probability vector for a given instance, as predicted by the model.\n",
    "        class_labels (list): A list of class labels, adjusted to be zero-based.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing a list of the top predicted classes and the most likely predicted class.\n",
    "    \"\"\"\n",
    "    # Sort the classes based on the probability vector and select the top N classes\n",
    "    top_pred_classes = probability_vector[0].argsort()[-len(class_labels):][::-1]\n",
    "    \n",
    "    # Use np.argmax to find the index of the maximum value in the probability vector\n",
    "    predicted_class_index = np.argmax(probability_vector, axis=1)\n",
    "    \n",
    "    # Map the predicted index to its corresponding class label\n",
    "    predicted_classes = [class_labels[i] for i in predicted_class_index]\n",
    "    \n",
    "    # Since we're predicting for one instance, access the first element for the predicted class\n",
    "    predicted_class = predicted_classes[0]\n",
    "    \n",
    "    return top_pred_classes, predicted_class\n",
    "\n",
    "\n",
    "def segment_ecg_signal(instance_ecg, num_slices=40):\n",
    "    \"\"\"\n",
    "    Segments an ECG signal into a fixed number of slices.\n",
    "\n",
    "    Parameters:\n",
    "        instance_ecg (np.ndarray): The ECG signal instance to segment.\n",
    "        num_slices (int): The number of slices to divide the signal into.\n",
    "\n",
    "    Returns:\n",
    "        int: The width of each slice in the segmented ECG signal.\n",
    "    \"\"\"\n",
    "    total_length = len(instance_ecg)\n",
    "    slice_width = total_length // num_slices\n",
    "    return slice_width\n",
    "\n",
    "def perturb_total_mean(signal, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Perturbs a segment of the signal by replacing it with the overall mean of the signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): The original signal to perturb.\n",
    "        start_idx (int): The starting index of the segment to perturb.\n",
    "        end_idx (int): The ending index of the segment to perturb.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The signal with the specified segment perturbed by the total mean.\n",
    "    \"\"\"\n",
    "    modified_signal = signal.copy()\n",
    "    modified_signal[start_idx:end_idx] = modified_signal.mean()\n",
    "    return modified_signal\n",
    "def perturb_mean_channel(signal, start_idx, end_idx, channel):\n",
    "    \"\"\"\n",
    "    Directly modifies a segment of the signal by replacing it with the mean of that segment. Accepts multichannel signals\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): The signal to perturb, modified in place.\n",
    "        start_idx (int): The starting index of the segment to perturb.\n",
    "        end_idx (int): The ending index of the segment to perturb.\n",
    "    \"\"\"\n",
    "    mean_value = np.mean(signal[start_idx:end_idx,channel])\n",
    "    signal[start_idx:end_idx,channel] = mean_value\n",
    "def perturb_mean(signal, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Directly modifies a segment of the signal by replacing it with the mean of that segment.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): The signal to perturb, modified in place.\n",
    "        start_idx (int): The starting index of the segment to perturb.\n",
    "        end_idx (int): The ending index of the segment to perturb.\n",
    "    \"\"\"\n",
    "    mean_value = np.mean(signal[start_idx:end_idx])\n",
    "    signal[start_idx:end_idx] = mean_value\n",
    "\n",
    "def perturb_noise(signal, start_idx, end_idx):\n",
    "    \"\"\"\n",
    "    Perturbs a segment of the signal by replacing it with random noise within the signal's range.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): The original signal to perturb.\n",
    "        start_idx (int): The starting index of the segment to perturb.\n",
    "        end_idx (int): The ending index of the segment to perturb.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The signal with the specified segment perturbed by random noise.\n",
    "    \"\"\"\n",
    "    modified_signal = signal.copy()\n",
    "    modified_signal[start_idx:end_idx] = np.random.uniform(modified_signal.min(), modified_signal.max(), end_idx - start_idx)\n",
    "    return modified_signal\n",
    "\n",
    "\n",
    "\n",
    "def apply_perturbation_to_ecg_channel_matrix(signal, perturbation, num_segments, channels,perturb_function=perturb_mean_channel):\n",
    "    \"\"\"\n",
    "    Apply a perturbation to an ECG signal with multiple channels.\n",
    "\n",
    "    Parameters:\n",
    "    - signal (np.ndarray): The original ECG signal.\n",
    "    - perturbation (np.ndarray): A vector indicating which segments to turn on (1) or off (0).\n",
    "    - num_segments (int): The total number of segments the ECG signal is divided into.\n",
    "    - perturb_function (function): The function to use for perturbing the signal (default is perturb_mean).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A perturbed version of the ECG signal.\n",
    "    \"\"\"\n",
    "    # Copy the signal to avoid modifying the original\n",
    "    perturbed_signal = copy.deepcopy(signal)\n",
    "    segment_length = len(signal) // num_segments\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(channels):\n",
    "    # Apply the perturbation based on the provided vector\n",
    "        for i, active in enumerate(perturbation[:,j]):\n",
    "            start_idx = i * segment_length\n",
    "            end_idx = start_idx + segment_length\n",
    "            # Apply perturbation function only to \"off\" segments\n",
    "            if not active:\n",
    "                perturb_mean_channel(perturbed_signal, start_idx, end_idx, j)\n",
    "\n",
    "    return perturbed_signal\n",
    "\n",
    "\n",
    "\n",
    "def predict_perturbations(model, instance_ecg, random_perturbations, num_slices, perturb_function, channel, channels):\n",
    "    \"\"\"\n",
    "    Applies a set of perturbations to an ECG signal, predicts the class probabilities for each perturbed signal,\n",
    "    and collects the predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained ECG classifier model.\n",
    "    - instance_ecg (np.ndarray): The original ECG signal instance.\n",
    "    - random_perturbations (np.ndarray): An array of perturbation vectors.\n",
    "    - num_slices (int): The total number of segments the ECG signal is divided into.\n",
    "    - perturb_function (function): The function to use for perturbing the signal (e.g., perturb_mean).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An array of model predictions for each perturbed ECG signal.\n",
    "    \"\"\"\n",
    "    perturbation_predictions = []\n",
    "\n",
    "    for perturbation in random_perturbations:\n",
    "        # Apply the current perturbation to the ECG signal\n",
    "        perturbed_signal = apply_perturbation_to_ecg_channel_matrix(instance_ecg, perturbation, num_slices,channels, perturb_function)\n",
    "\n",
    "        # Reshape as required by the model\n",
    "        perturbed_signal_reshaped = perturbed_signal.reshape(1, len(perturbed_signal), channels)  \n",
    "\n",
    "        # Predict the class probabilities\n",
    "        model_prediction = model.predict(perturbed_signal_reshaped)\n",
    "        perturbation_predictions.append(model_prediction)\n",
    "\n",
    "    # Convert the list of predictions into a numpy array\n",
    "    perturbation_predictions = np.array(perturbation_predictions)\n",
    "    return perturbation_predictions\n",
    "\n",
    "def calculate_cosine_distances(random_perturbations, num_slices):\n",
    "    \"\"\"\n",
    "    Calculates the cosine distances between each perturbation vector and the original signal representation.\n",
    "\n",
    "    Parameters:\n",
    "    - random_perturbations (np.ndarray): An array of perturbation vectors.\n",
    "    - num_slices (int): The total number of segments the ECG signal is divided into, matching the dimension of the perturbations.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An array of cosine distances for each perturbation from the original signal representation.\n",
    "    \"\"\"\n",
    "    random_perturbations_flattened=np.zeros((random_perturbations.shape[0],random_perturbations.shape[1]*8))\n",
    "    for j in range(random_perturbations.shape[0]):\n",
    "        random_perturbations_flattened[j,:]= random_perturbations[j,:,:].ravel()   \n",
    "        \n",
    "    # Represent the original ECG signal as a perturbation where all segments are enabled (i.e., a vector of ones)\n",
    "    original_ecg_rep = np.ones((1, num_slices*8))\n",
    "\n",
    "    # Calculate cosine distances\n",
    "    cosine_distances = pairwise_distances(random_perturbations_flattened, original_ecg_rep, metric='cosine').ravel()\n",
    "\n",
    "    return cosine_distances\n",
    "\n",
    "def calculate_weights_from_distances(cosine_distances, kernel_width=0.25):\n",
    "    \"\"\"\n",
    "    Applies a kernel function to cosine distances to calculate weights for each perturbation.\n",
    "\n",
    "    Parameters:\n",
    "    - cosine_distances (np.ndarray): An array of cosine distances for each perturbation from the original signal representation.\n",
    "    - kernel_width (float): The kernel width parameter for the exponential kernel function. Default is 0.25.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An array of weights for each perturbation, derived from the cosine distances.\n",
    "    \"\"\"\n",
    " \n",
    "    weights = np.sqrt(np.exp(-(cosine_distances ** 2) / kernel_width ** 2))\n",
    "    return weights\n",
    "\n",
    "def fit_explainable_model(perturbation_predictions, random_perturbations, weights, target_class):\n",
    "    \"\"\"\n",
    "    Fits a linear regression model to quantify the importance of each segment \n",
    "    in the decision-making process for the target class.\n",
    "\n",
    "    Parameters:\n",
    "    - perturbation_predictions (np.ndarray): The array of model predictions for each perturbed ECG signal.\n",
    "    - random_perturbations (np.ndarray): The matrix of perturbation vectors.\n",
    "    - weights (np.ndarray): The array of weights corresponding to each perturbation.\n",
    "    - target_class (int): The index of the target class to explain.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The coefficients of the linear regression model, indicating the importance of each segment.\n",
    "    \"\"\"\n",
    "    # Initialize the linear regression model\n",
    "    explainable_model = LinearRegression()\n",
    "\n",
    "    # Squeeze the middle dimension out from perturbation_predictions to get a 2D array\n",
    "    perturbation_predictions_squeezed = np.squeeze(perturbation_predictions, axis=1)\n",
    "\n",
    "    # Select the predictions for the target class across all perturbations\n",
    "    target_predictions = perturbation_predictions_squeezed[:, target_class]\n",
    "    \n",
    "    random_perturbations_flattened=np.zeros((random_perturbations.shape[0],random_perturbations.shape[1]*8))\n",
    "    for j in range(random_perturbations.shape[0]):\n",
    "        random_perturbations_flattened[j,:]= random_perturbations[j,:,:].ravel()\n",
    "    # Fit the model\n",
    "    explainable_model.fit(X=random_perturbations_flattened, y=target_predictions, sample_weight=weights)\n",
    "\n",
    "    # Extract the coefficients\n",
    "    segment_importance_coefficients = explainable_model.coef_\n",
    "\n",
    "    return segment_importance_coefficients\n",
    "\n",
    "\n",
    "def identify_top_influential_segments(segment_importance_coefficients, number_of_top_features=5):\n",
    "    \"\"\"\n",
    "    Identifies the top influential segments of an ECG signal based on the importance coefficients \n",
    "    obtained from a linear regression model.\n",
    "\n",
    "    Parameters:\n",
    "    - segment_importance_coefficients (np.ndarray): The coefficients indicating the importance of each segment.\n",
    "    - number_of_top_features (int): The number of top influential segments to identify.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Indices of the top influential segments.\n",
    "    \"\"\"\n",
    "    # Sort the coefficients based on their absolute magnitude to identify the most influential segments\n",
    "    top_influential_segments = np.argsort(np.abs(segment_importance_coefficients))[-number_of_top_features:]\n",
    "    \n",
    "    return top_influential_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9730002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(  model, X_test, id_ecg ,electrodo,number_of_top_features,num_perturbations = 200,num_slices = 50, channels=8):\n",
    "    \n",
    "    #model= Trained model\n",
    "    #X_test= test dataset\n",
    "    #id_ecg= number of trial in test dataset\n",
    "    #electrodo= list of electrodes names\n",
    "    #number_of_top_features= desired number of top features\n",
    "    #num_perturbations= number of random perturbations applied to the signals\n",
    "    #num_slices= number of time segments the signals get split into\n",
    "    \n",
    "    instance_ecg = X_test[id_ecg, :]     \n",
    "\n",
    "    # Predict the class of the selected signal by trained model\n",
    "    probability_vector = model.predict(instance_ecg[np.newaxis, :])\n",
    "\n",
    "    # class labels\n",
    "    class_labels = [0, 1]\n",
    "\n",
    "    print(instance_ecg.shape)\n",
    "    top_pred_classes, predicted_class = analyze_prediction(probability_vector, class_labels)\n",
    "\n",
    "\n",
    "    slice_width = segment_ecg_signal(instance_ecg, num_slices)\n",
    "\n",
    "    random_perturbations = generate_random_perturbations_matrix(num_perturbations, num_slices,channels)\n",
    "    \n",
    "    \n",
    "    perturbation_predictions = predict_perturbations(model, instance_ecg, random_perturbations, num_slices, perturb_mean_channel,0,channels)\n",
    "\n",
    "# Calculate cosine distances between each perturbation and the original ECG signal representation\n",
    "    cosine_distances = calculate_cosine_distances(random_perturbations, num_slices)\n",
    "\n",
    "#Applying a Kernel Function to Compute Weights\n",
    "    kernel_width = 0.25  # This can be adjusted based on your specific needs\n",
    "    weights = calculate_weights_from_distances(cosine_distances, kernel_width)\n",
    "\n",
    "    # Now we have the weights for each perturbation for further analysis\n",
    "\n",
    "# Constructing the Explainable Model for ECG Signals\n",
    "    segment_importance_coefficients = fit_explainable_model(perturbation_predictions, random_perturbations, weights, target_class=top_pred_classes[0])\n",
    "\n",
    "    # The importance coefficients for each segment\n",
    "# Isolating Influential Signal Segments\n",
    "    print(segment_importance_coefficients.shape)\n",
    "    top_influential_segments = identify_top_influential_segments(segment_importance_coefficients, number_of_top_features)\n",
    "\n",
    "# The indices of the top influential segments\n",
    "    print(\"Top Influential Signal Segments:\", top_influential_segments)\n",
    "# Visualizing the LIME Explanation: Highlighting Key Segments\n",
    "    results= np.zeros((channels,num_slices))\n",
    "    for i in range(channels):\n",
    "        for j in top_influential_segments:\n",
    "            if j<i*30+30 and j>=i*30:\n",
    "                results[i][j-i*30]=1\n",
    "         \n",
    "    res= pd.DataFrame(results)\n",
    "    res['electrodo']=np.concatenate([electrodo,electrodo])\n",
    "\n",
    "    res['hg/b']= [\"High Gamma\"] * len(electrodes) + [\"Beta\"] * len(electrodes)\n",
    "    res['true class']=y_test[id_ecg].argmax()\n",
    "    res['predicted_class']= predicted_class\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646940d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for j in range(X_test.shape[0]):\n",
    "    results.append(get_segments(  model, X_test, j,electrodes,number_of_top_features=80,num_perturbations = 300,num_slices = 30,channels=8))\n",
    "    \n",
    "\n",
    "pd.concat(results).to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
